{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0315c03",
   "metadata": {},
   "source": [
    "# Insurance Claim Risk Classification\n",
    "\n",
    "## 🎯 Problem Statement  \n",
    "Develop a binary classifier to predict whether an insurance applicant will file **high-cost claims** (above \\$10,000/year) based on their demographic and health profile. This helps insurers:  \n",
    "1. Flag high-risk applicants for additional medical underwriting  \n",
    "2. Design tiered insurance plans  \n",
    "3. Optimize risk pools  \n",
    "\n",
    "**Key Difference from Regression**:  \n",
    "While the regression model predicts exact costs, this classifier identifies risk categories for decision automation.\n",
    "\n",
    "## 📊 Target Variable Engineering  \n",
    "Create binary label from existing `charges` column:  \n",
    "```python\n",
    "df['high_risk'] = (df['charges'] > 10000).astype(int)  # Threshold based on 75th percentile\n",
    "```\n",
    "\n",
    "## Proposed Analysis Flow\n",
    "1.  Baseline Classification\n",
    "**Models to Compare**:\n",
    "\n",
    "| Model               | Pros                                      | Cons                                      | Best Use Cases                          |\n",
    "|---------------------|------------------------------------------|------------------------------------------|-----------------------------------------|\n",
    "| **Logistic Regression** | - Simple to implement<br>- Highly interpretable<br>- Fast training time | - Linear decision boundary<br>- Struggles with complex patterns<br>- Requires feature scaling | Baseline models<br>When interpretability is critical<br>Low-dimensional data |\n",
    "| **Decision Tree**   | - No need for feature scaling<br>- Handles non-linear relationships<br>- Interpretable rules | - Prone to overfitting<br>- Unstable (small changes affect tree)<br>- Poor generalization | Rule-based systems<br>Feature importance analysis<br>Data with mixed types |\n",
    "| **Random Forest**   | - Reduces overfitting vs single trees<br>- Handles high dimensions well<br>- Feature importance scores | - Less interpretable than single trees<br>- Slower prediction time<br>- Memory intensive | Medium-large datasets<br>When accuracy > interpretability<br>Non-linear relationships |\n",
    "| **XGBoost**        | - State-of-the-art accuracy<br>- Built-in regularization<br>- Handles missing values | - Complex hyperparameter tuning<br>- Computationally expensive<br>- Black box nature | Competitions/kaggle<br>Imbalanced datasets<br>When performance is critical |\n",
    "| **LightGBM**       | - **Faster training** than XGBoost<br>- **Lower memory** usage<br>- Handles categorical features natively | - More prone to overfitting on small data<br>- Less robust to noisy data | **Large datasets**<br>**Real-time applications**<br>When speed is critical |\n",
    "| **SVM**            | - Effective in high dimensions<br>- Versatile kernel options<br>- Good for small datasets | - Computationally heavy<br>- Difficult to tune<br>- Poor scalability | Small-medium datasets<br>Clear margin separation<br>Text classification |\n",
    "| **Naive Bayes**    | - Extremely fast<br>- Works well with small data<br>- Low memory usage | - Strong independence assumptions<br>- Poor with correlated features<br>- Underfitting risk | Text classification<br>Real-time predictions<br>As a baseline model |\n",
    "| **Neural Networks** | - Handles complex patterns<br>- Feature extraction capability<br>- State-of-the-art performance | - Requires large data<br>- Computationally expensive<br>- Black box | Image/audio/text data<br>When other models plateau<br>With sufficient resources |\n",
    "\n",
    "**Key Selection Criteria**:\n",
    "1. **Speed**: LightGBM > XGBoost > Random Forest > Logistic Regression\n",
    "2. **Accuracy**: XGBoost ≈ LightGBM > Random Forest > Neural Nets (with enough data)\n",
    "3. **Memory Efficiency**: LightGBM > Random Forest > XGBoost\n",
    "4. **Categorical Data**: LightGBM (native handling) > Others (require encoding)\n",
    "\n",
    "\n",
    "**Key Selection Criteria**:\n",
    "\n",
    "- **Interpretability**:  \n",
    "  `Logistic Regression > Decision Tree > Random Forest > XGBoost > Neural Nets`  \n",
    "\n",
    "- **Training Speed**:  \n",
    "  `Naive Bayes > Logistic Regression > Decision Tree > Random Forest > XGBoost`  \n",
    "\n",
    "- **Handling Non-linearity**:  \n",
    "  `Neural Nets > XGBoost > SVM > Random Forest > Decision Tree`\n",
    "\n",
    "## 🛠️  Exploratory Data Analysis (EDA)\n",
    "Example classification task comparing smokers/non-smokers:\n",
    "- Creates a percentage frequency table showing the distribution of high_risk classifications across different smoking statuses.\n",
    "\n",
    "```python\n",
    "pd.crosstab(df['smoker'], df['high_risk'], normalize='index')*100\n",
    "```\n",
    "\n",
    "**Metrics**：\n",
    "```python\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "```\n",
    "2. Feature Importance Analysis (Notebook Section 2)\n",
    "Identify top risk drivers using:\n",
    "```python\n",
    "import shap\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "```\n",
    "3. Business Rule Extraction\n",
    "Convert model insights into underwriting rules:\n",
    "```python\n",
    "from sklearn.tree import export_text\n",
    "print(export_text(decision_tree, feature_names=X.columns))\n",
    "```\n",
    "Example rule:\n",
    "IF smoker=YES AND BMI>30 THEN high_risk_prob=82%\n",
    "\n",
    "## Expected Deliverables\n",
    "1. Model Performance Report: \n",
    "- Precision/recall for high-risk class\n",
    "\n",
    "2. Risk Probability Calculator:\n",
    "```python\n",
    "def risk_calculator(age, bmi, smoker):\n",
    "    return model.predict_proba([[age, bmi, smoker]])[0][1]\n",
    "```\n",
    "3. Underwriting Recommendations: \n",
    "- List of high-risk combinations to screen\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9f1e8c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Introduction to Loss Functions in Classification\n",
    "\n",
    "## What is a Loss Function?\n",
    "A loss function measures how wrong a model's predictions are compared to the true values. It gives the model a way to calculate its mistakes and improve during training.\n",
    "\n",
    "## Key Properties of Loss Functions\n",
    "- **Differentiable**: Can calculate gradients for optimization\n",
    "- **Task-Specific**: Different problems need different loss types\n",
    "- **Robustness**: Some handle unusual data points better than others\n",
    "\n",
    "## Common Loss Functions\n",
    "\n",
    "### Cross-Entropy Loss\n",
    "Used by logistic regression and neural networks. It heavily penalizes confident but wrong predictions.\n",
    "\n",
    "### Gini Impurity\n",
    "Used by decision trees and random forests. Measures how often a random sample would be misclassified.\n",
    "\n",
    "### Hinge Loss\n",
    "Used by support vector machines (SVMs). Focuses only on predictions near the decision boundary.\n",
    "\n",
    "### Focal Loss\n",
    "Specialized for imbalanced data. Pays more attention to hard-to-classify examples.\n",
    "\n",
    "## How Models Choose Loss\n",
    "Most models automatically pick a suitable loss function based on:\n",
    "- Number of classes (binary vs multiclass)\n",
    "- Type of problem (classification vs regression)\n",
    "- Model architecture (trees vs neural networks)\n",
    "\n",
    "## Practical Recommendations\n",
    "1. Start with default loss functions - they usually work well\n",
    "2. For imbalanced data, use weighted or specialized losses\n",
    "3. For custom needs, some models allow creating your own loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b3aaec",
   "metadata": {},
   "source": [
    "# Classification Evaluation Metrics\n",
    "\n",
    "## Core Metrics\n",
    "\n",
    "### 1. **Accuracy**\n",
    "```\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "```\n",
    "- **Pros**: Easy to interpret\n",
    "- **Cons**: Misleading for imbalanced datasets\n",
    "- **When to use**: Balanced classes, quick sanity check\n",
    "\n",
    "### 2. **Precision**\n",
    "```\n",
    "Precision = TP / (TP + FP)\n",
    "```\n",
    "- Measures: \"How many selected items are relevant?\"\n",
    "- Focus: False positives\n",
    "- **Use case**: Spam detection (minimize false positives)\n",
    "\n",
    "### 3. **Recall (Sensitivity)**\n",
    "```\n",
    "Recall = TP / (TP + FN)\n",
    "```\n",
    "- Measures: \"How many relevant items are selected?\"\n",
    "- Focus: False negatives\n",
    "- **Use case**: Cancer detection (minimize false negatives)\n",
    "\n",
    "### 4. **F1-Score**\n",
    "```\n",
    "F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "```\n",
    "- Harmonic mean of precision and recall\n",
    "- **Best for**: Imbalanced datasets\n",
    "\n",
    "## Advanced Metrics\n",
    "\n",
    "### 5. **ROC-AUC**\n",
    "- Measures model's ability to distinguish classes\n",
    "- **Range**: 0.5 (random) to 1.0 (perfect)\n",
    "- **Good for**: Binary classification with balanced data\n",
    "\n",
    "### 6. **Precision-Recall Curve**\n",
    "- Better than ROC for imbalanced data\n",
    "- Shows tradeoff between precision/recall\n",
    "\n",
    "### 7. **Confusion Matrix**\n",
    "|                     | Predicted Negative | Predicted Positive |\n",
    "|---------------------|--------------------|--------------------|\n",
    "| **Actual Negative** | True Negative (TN) | False Positive (FP)|\n",
    "| **Actual Positive** | False Negative (FN)| True Positive (TP) |\n",
    "- Visualizes all error types\n",
    "- Foundation for other metrics\n",
    "\n",
    "## Special Cases\n",
    "\n",
    "### For Multi-class:\n",
    "- **Macro-average**: Treats all classes equally\n",
    "- **Micro-average**: Aggregates all TP/FP/FN/TN\n",
    "\n",
    "### For Imbalanced Data:\n",
    "- **Cohen's Kappa**: Measures agreement accounting for chance\n",
    "- **MCC (Matthews Correlation)**: Balanced measure (-1 to +1)\n",
    "\n",
    "## Metric Selection Guide\n",
    "\n",
    "| Scenario                  | Recommended Metrics                  |\n",
    "|---------------------------|--------------------------------------|\n",
    "| Balanced binary class     | Accuracy, ROC-AUC                   |\n",
    "| Imbalanced binary class   | F1, Precision-Recall Curve          |\n",
    "| Multi-class               | Macro-F1, Weighted Accuracy         |\n",
    "| High FP cost              | Precision                           |\n",
    "| High FN cost              | Recall                              |\n",
    "| Comprehensive evaluation  | Confusion Matrix + Multiple Metrics |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5547f0",
   "metadata": {},
   "source": [
    "# Classification Model Implementation Guide\n",
    "\n",
    "## 1. Data Preparation\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features and target\n",
    "X = df[['age', 'bmi', 'smoker', 'children']]  # Features\n",
    "y = df['high_risk']  # Target (binary)\n",
    "\n",
    "# Convert categoricals (smoker: yes/no → 1/0)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split data (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "```\n",
    "2. Model Training\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create pipeline with preprocessing + model\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        class_weight='balanced',  # Handles class imbalance\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "3. Prediction\n",
    "```python\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)  # Class predictions (0/1)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probability scores\n",
    "\n",
    "# Predict for new applicant\n",
    "new_applicant = [[45, 28.5, 1, 2]]  # Age, BMI, Smoker (1=yes), Children\n",
    "risk_prediction = model.predict(new_applicant)\n",
    "risk_probability = model.predict_proba(new_applicant)[0][1]\n",
    "```\n",
    "4. Evaluation\n",
    "```python\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Classification metrics\n",
    "print(classification_report(y_test, y_pred, target_names=['Low Risk', 'High Risk']))\n",
    "\n",
    "# AUC-ROC score\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, y_proba):.2f}\")\n",
    "\n",
    "# Feature importance\n",
    "importances = model.named_steps['randomforestclassifier'].feature_importances_\n",
    "pd.Series(importances, index=X.columns).sort_values().plot(kind='barh')\n",
    "```\n",
    "5. Model Deployment\n",
    "```python\n",
    "import joblib\n",
    "\n",
    "# Save model\n",
    "joblib.dump(model, 'risk_classifier.pkl')\n",
    "\n",
    "# Load in production\n",
    "production_model = joblib.load('risk_classifier.pkl')\n",
    "\n",
    "# API endpoint example (Flask)\n",
    "from flask import Flask, request, jsonify\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json()\n",
    "    prediction = production_model.predict([data['features']])\n",
    "    return jsonify({'risk_level': int(prediction[0])})\n",
    "```\n",
    "6. Monitoring (Optional)\n",
    "\n",
    "```python\n",
    "# Drift detection\n",
    "from alibi_detect import KSDrift\n",
    "\n",
    "drift_detector = KSDrift(X_train, p_val=0.05)\n",
    "drift = drift_detector.predict(X_test)\n",
    "print(f\"Data drift detected: {drift['data']['is_drift']}\")\n",
    "```\n",
    "```\n",
    "graph TD\n",
    "    A[Raw Data] --> B[Preprocessing]\n",
    "    B --> C[Train/Test Split]\n",
    "    C --> D[Model Training]\n",
    "    D --> E[Evaluation]\n",
    "    E --> F[Deployment]\n",
    "    F --> G[Monitoring]\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
